-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
-- Set this variable to avoid using a hard-coded path each time query
-- results are compared
\set QUERY_RESULT_TEST_EQUAL_RELPATH '../../../test/sql/include/query_result_test_equal.sql'
\set ON_ERROR_STOP 0
--DDL commands on continuous aggregates
CREATE TABLE conditions (
      timec        TIMESTAMPTZ       NOT NULL,
      location    TEXT              NOT NULL,
      temperature integer  NULL,
      humidity    DOUBLE PRECISION  NULL,
      timemeasure TIMESTAMPTZ,
      timeinterval INTERVAL
);
select table_name from create_hypertable('conditions', 'timec');
 table_name 
------------
 conditions
(1 row)

-- schema tests
\c :TEST_DBNAME :ROLE_SUPERUSER
CREATE SCHEMA rename_schema;
GRANT ALL ON SCHEMA rename_schema TO :ROLE_DEFAULT_PERM_USER;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
CREATE TABLE foo(time TIMESTAMPTZ, data INTEGER);
SELECT create_hypertable('foo', 'time');
NOTICE:  adding not-null constraint to column "time"
 create_hypertable 
-------------------
 (2,public,foo,t)
(1 row)

CREATE VIEW rename_test
  WITH ( timescaledb.continuous, timescaledb.materialized_only=true)
AS SELECT time_bucket('1week', time), COUNT(data)
    FROM foo
    GROUP BY 1;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  partial_view_schema  | partial_view_name 
------------------+----------------+-----------------------+-------------------
 public           | rename_test    | _timescaledb_internal | _partial_view_3
(1 row)

ALTER VIEW rename_test SET SCHEMA rename_schema;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  partial_view_schema  | partial_view_name 
------------------+----------------+-----------------------+-------------------
 rename_schema    | rename_test    | _timescaledb_internal | _partial_view_3
(1 row)

SELECT ca.raw_hypertable_id as "RAW_HYPERTABLE_ID",
       h.schema_name AS "MAT_SCHEMA_NAME",
       h.table_name AS "MAT_TABLE_NAME",
       partial_view_name as "PART_VIEW_NAME",
       partial_view_schema as "PART_VIEW_SCHEMA",
       direct_view_name as "DIR_VIEW_NAME",
       direct_view_schema as "DIR_VIEW_SCHEMA"
FROM _timescaledb_catalog.continuous_agg ca
INNER JOIN _timescaledb_catalog.hypertable h ON(h.id = ca.mat_hypertable_id)
WHERE user_view_name = 'rename_test'
\gset
\c :TEST_DBNAME :ROLE_SUPERUSER
ALTER VIEW :"PART_VIEW_SCHEMA".:"PART_VIEW_NAME" SET SCHEMA public;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name | partial_view_schema | partial_view_name 
------------------+----------------+---------------------+-------------------
 rename_schema    | rename_test    | public              | _partial_view_3
(1 row)

--alter direct view schema
SELECT user_view_schema, user_view_name, direct_view_schema, direct_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name |  direct_view_schema   | direct_view_name 
------------------+----------------+-----------------------+------------------
 rename_schema    | rename_test    | _timescaledb_internal | _direct_view_3
(1 row)

\c :TEST_DBNAME :ROLE_SUPERUSER
ALTER VIEW :"DIR_VIEW_SCHEMA".:"DIR_VIEW_NAME" SET SCHEMA public;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name,
      direct_view_schema, direct_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name | partial_view_schema | partial_view_name | direct_view_schema | direct_view_name 
------------------+----------------+---------------------+-------------------+--------------------+------------------
 rename_schema    | rename_test    | public              | _partial_view_3   | public             | _direct_view_3
(1 row)

\c :TEST_DBNAME :ROLE_SUPERUSER
ALTER SCHEMA rename_schema RENAME TO new_name_schema;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name | partial_view_schema | partial_view_name 
------------------+----------------+---------------------+-------------------
 new_name_schema  | rename_test    | public              | _partial_view_3
(1 row)

ALTER VIEW :"PART_VIEW_NAME" SET SCHEMA new_name_schema;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name | partial_view_schema | partial_view_name 
------------------+----------------+---------------------+-------------------
 new_name_schema  | rename_test    | new_name_schema     | _partial_view_3
(1 row)

\c :TEST_DBNAME :ROLE_SUPERUSER
ALTER SCHEMA new_name_schema RENAME TO foo_name_schema;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name | partial_view_schema | partial_view_name 
------------------+----------------+---------------------+-------------------
 foo_name_schema  | rename_test    | foo_name_schema     | _partial_view_3
(1 row)

ALTER VIEW foo_name_schema.rename_test SET SCHEMA public;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name | partial_view_schema | partial_view_name 
------------------+----------------+---------------------+-------------------
 public           | rename_test    | foo_name_schema     | _partial_view_3
(1 row)

\c :TEST_DBNAME :ROLE_SUPERUSER
ALTER SCHEMA foo_name_schema RENAME TO rename_schema;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
SET client_min_messages TO LOG;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema | user_view_name | partial_view_schema | partial_view_name 
------------------+----------------+---------------------+-------------------
 public           | rename_test    | rename_schema       | _partial_view_3
(1 row)

ALTER VIEW rename_test RENAME TO rename_c_aggregate;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema |   user_view_name   | partial_view_schema | partial_view_name 
------------------+--------------------+---------------------+-------------------
 public           | rename_c_aggregate | rename_schema       | _partial_view_3
(1 row)

SELECT * FROM rename_c_aggregate;
 time_bucket | count 
-------------+-------
(0 rows)

ALTER VIEW rename_schema.:"PART_VIEW_NAME" RENAME TO partial_view;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name,
      direct_view_schema, direct_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema |   user_view_name   | partial_view_schema | partial_view_name | direct_view_schema | direct_view_name 
------------------+--------------------+---------------------+-------------------+--------------------+------------------
 public           | rename_c_aggregate | rename_schema       | partial_view      | public             | _direct_view_3
(1 row)

--rename direct view
ALTER VIEW :"DIR_VIEW_NAME" RENAME TO direct_view;
SELECT user_view_schema, user_view_name, partial_view_schema, partial_view_name,
      direct_view_schema, direct_view_name
      FROM _timescaledb_catalog.continuous_agg;
 user_view_schema |   user_view_name   | partial_view_schema | partial_view_name | direct_view_schema | direct_view_name 
------------------+--------------------+---------------------+-------------------+--------------------+------------------
 public           | rename_c_aggregate | rename_schema       | partial_view      | public             | direct_view
(1 row)

-- drop_chunks tests
DROP TABLE conditions CASCADE;
DROP TABLE foo CASCADE;
NOTICE:  drop cascades to 2 other objects
CREATE TABLE drop_chunks_table(time BIGINT, data INTEGER);
SELECT hypertable_id AS drop_chunks_table_id
    FROM create_hypertable('drop_chunks_table', 'time', chunk_time_interval => 10) \gset
NOTICE:  adding not-null constraint to column "time"
CREATE OR REPLACE FUNCTION integer_now_test() returns bigint LANGUAGE SQL STABLE as $$ SELECT coalesce(max(time), bigint '0') FROM drop_chunks_table $$;
SELECT set_integer_now_func('drop_chunks_table', 'integer_now_test');
 set_integer_now_func 
----------------------
 
(1 row)

CREATE VIEW drop_chunks_view
  WITH (
    timescaledb.continuous,
    timescaledb.materialized_only=true,
    timescaledb.refresh_interval='72 hours'
  )
AS SELECT time_bucket('5', time), COUNT(data)
    FROM drop_chunks_table
    GROUP BY 1;
SELECT format('%s.%s', schema_name, table_name) AS drop_chunks_mat_table,
        schema_name AS drop_chunks_mat_schema,
        table_name AS drop_chunks_mat_table_name
    FROM _timescaledb_catalog.hypertable, _timescaledb_catalog.continuous_agg
    WHERE _timescaledb_catalog.continuous_agg.raw_hypertable_id = :drop_chunks_table_id
        AND _timescaledb_catalog.hypertable.id = _timescaledb_catalog.continuous_agg.mat_hypertable_id \gset
-- create 3 chunks, with 3 time bucket
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(0, 29) AS i;
REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 15
SELECT count(c) FROM show_chunks('drop_chunks_table') AS c;
 count 
-------
     3
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           0 |     5
           5 |     5
          10 |     5
(3 rows)

-- cannot drop directly from the materialization table without specifying
-- cont. aggregate view name explicitly
\set ON_ERROR_STOP 0
SELECT drop_chunks(
    newer_than => -20,
    verbose => true,
    cascade_to_materializations=>true);
INFO:  dropping chunk _timescaledb_internal._hyper_4_1_chunk
INFO:  dropping chunk _timescaledb_internal._hyper_4_2_chunk
INFO:  dropping chunk _timescaledb_internal._hyper_4_3_chunk
ERROR:  cannot drop chunks on a continuous aggregate materialization table
\set ON_ERROR_STOP 1
SELECT count(c) FROM show_chunks('drop_chunks_table') AS c;
 count 
-------
     3
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           0 |     5
           5 |     5
          10 |     5
(3 rows)

-- cannot drop from the raw table without specifying cascade_to_materializations
\set ON_ERROR_STOP 0
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => 10);
ERROR:  cascade_to_materializations options must be set explicitly
\set ON_ERROR_STOP 1
SELECT count(c) FROM show_chunks('drop_chunks_table') AS c;
 count 
-------
     3
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           0 |     5
           5 |     5
          10 |     5
(3 rows)

\set ON_ERROR_STOP 0
SELECT drop_chunks(older_than => 200);
ERROR:  cascade_to_materializations options must be set explicitly
\set ON_ERROR_STOP 1
SELECT count(c) FROM show_chunks('drop_chunks_table') AS c;
 count 
-------
     3
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           0 |     5
           5 |     5
          10 |     5
(3 rows)

-- show_chunks and drop_chunks output should be the same
\set QUERY1 'SELECT show_chunks(hypertable => \'drop_chunks_table\', older_than => 13)::REGCLASS::TEXT'
\set QUERY2 'SELECT drop_chunks(table_name => \'drop_chunks_table\', older_than => 13, cascade_to_materializations => true)::TEXT'
\set ECHO errors
 Different Rows | Total Rows from Query 1 | Total Rows from Query 2 
----------------+-------------------------+-------------------------
              0 |                       1 |                       1
(1 row)

SELECT count(c) FROM show_chunks('drop_chunks_table') AS c;
 count 
-------
     2
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
          10 |     5
(1 row)

-- drop chunks when the chunksize and time_bucket aren't aligned
DROP TABLE drop_chunks_table CASCADE;
NOTICE:  drop cascades to 2 other objects
NOTICE:  drop cascades to table _timescaledb_internal._hyper_5_4_chunk
CREATE TABLE drop_chunks_table_u(time BIGINT, data INTEGER);
SELECT hypertable_id AS drop_chunks_table_u_id
    FROM create_hypertable('drop_chunks_table_u', 'time', chunk_time_interval => 7) \gset
NOTICE:  adding not-null constraint to column "time"
CREATE OR REPLACE FUNCTION integer_now_test1() returns bigint LANGUAGE SQL STABLE as $$ SELECT coalesce(max(time), bigint '0') FROM drop_chunks_table_u $$;
SELECT set_integer_now_func('drop_chunks_table_u', 'integer_now_test1');
 set_integer_now_func 
----------------------
 
(1 row)

CREATE VIEW drop_chunks_view
  WITH (
    timescaledb.continuous,
    timescaledb.materialized_only=true,
    timescaledb.refresh_interval='72 hours'
  )
AS SELECT time_bucket('3', time), COUNT(data)
    FROM drop_chunks_table_u
    GROUP BY 1;
SELECT format('%s.%s', schema_name, table_name) AS drop_chunks_mat_table_u,
        schema_name AS drop_chunks_mat_schema,
        table_name AS drop_chunks_mat_table_u_name
    FROM _timescaledb_catalog.hypertable, _timescaledb_catalog.continuous_agg
    WHERE _timescaledb_catalog.continuous_agg.raw_hypertable_id = :drop_chunks_table_u_id
        AND _timescaledb_catalog.hypertable.id = _timescaledb_catalog.continuous_agg.mat_hypertable_id \gset
-- create 3 chunks, with 3 time bucket
INSERT INTO drop_chunks_table_u SELECT i, i FROM generate_series(0, 21) AS i;
REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 15
SELECT count(c) FROM show_chunks('drop_chunks_table_u') AS c;
 count 
-------
     4
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table_u') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           0 |     3
           3 |     3
           6 |     3
           9 |     3
          12 |     3
(5 rows)

-- show_chunks and drop_chunks output should be the same
\set QUERY1 'SELECT show_chunks(hypertable => \'drop_chunks_table_u\', older_than => 13)::REGCLASS::TEXT'
\set QUERY2 'SELECT drop_chunks(table_name => \'drop_chunks_table_u\', older_than => 13, cascade_to_materializations => true)::TEXT'
\set ECHO errors
 Different Rows | Total Rows from Query 1 | Total Rows from Query 2 
----------------+-------------------------+-------------------------
              0 |                       1 |                       1
(1 row)

-- everything in the first chunk (values within [0, 6]) should be dropped
-- the time_bucket [6, 8] will lose it's first value, but should still have
-- the other two
SELECT count(c) FROM show_chunks('drop_chunks_table_u') AS c;
 count 
-------
     3
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_table_u') AS c;
 count 
-------
     1
(1 row)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           6 |     2
           9 |     3
          12 |     3
(3 rows)

-- TRUNCATE test
\set ON_ERROR_STOP 0
TRUNCATE drop_chunks_table_u;
ERROR:  cannot TRUNCATE a hypertable that has a continuous aggregate
TRUNCATE :drop_chunks_mat_table_u;
ERROR:  cannot TRUNCATE a hypertable underlying a continuous aggregate
\set ON_ERROR_STOP 1
-- ALTER TABLE tests
\set ON_ERROR_STOP 0
-- test a variety of ALTER TABLE statements
ALTER TABLE :drop_chunks_mat_table_u RENAME chunk_id TO bad_name;
ERROR:  cannot rename column "chunk_id" of materialization table "_materialized_hypertable_7"
ALTER TABLE :drop_chunks_mat_table_u ADD UNIQUE(chunk_id);
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u SET UNLOGGED;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u ENABLE ROW LEVEL SECURITY;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u ADD COLUMN fizzle INTEGER;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u DROP COLUMN chunk_id;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u ALTER COLUMN chunk_id DROP NOT NULL;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u ALTER COLUMN chunk_id SET DEFAULT 1;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u ALTER COLUMN chunk_id SET STORAGE EXTERNAL;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u DISABLE TRIGGER ALL;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u SET TABLESPACE foo;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u NOT OF;
ERROR:  operation not supported on materialization tables
ALTER TABLE :drop_chunks_mat_table_u OWNER TO CURRENT_USER;
ERROR:  operation not supported on materialization tables
\set ON_ERROR_STOP 1
ALTER TABLE :drop_chunks_mat_table_u SET SCHEMA public;
ALTER TABLE :drop_chunks_mat_table_u_name RENAME TO new_name;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
SET client_min_messages TO LOG;
CREATE INDEX new_name_idx ON new_name(chunk_id);
SELECT * FROM new_name;
 time_bucket |      agg_2_2       | chunk_id 
-------------+--------------------+----------
           6 | \x0000000000000002 |        6
           9 | \x0000000000000003 |        6
          12 | \x0000000000000002 |        6
          12 | \x0000000000000001 |        7
(4 rows)

SELECT * FROM drop_chunks_view ORDER BY 1;
 time_bucket | count 
-------------+-------
           6 |     2
           9 |     3
          12 |     3
(3 rows)

\set ON_ERROR_STOP 0
-- no continuous aggregates on a continuous aggregate materialization table
CREATE VIEW new_name_view
  WITH (
    timescaledb.continuous,
    timescaledb.materialized_only=true,
    timescaledb.refresh_interval='72 hours'
  )
AS SELECT time_bucket('6', time_bucket), COUNT(agg_2_2)
    FROM new_name
    GROUP BY 1;
ERROR:  hypertable is a continuous aggregate materialization table
-- cannot create a continuous aggregate on a continuous aggregate view
CREATE VIEW drop_chunks_view_view
  WITH (
    timescaledb.continuous,
    timescaledb.materialized_only=true,
    timescaledb.refresh_interval='72 hours'
  )
AS SELECT time_bucket('6', time_bucket), SUM(count)
    FROM drop_chunks_view
    GROUP BY 1;
ERROR:  invalid SELECT query for continuous aggregate
\set ON_ERROR_STOP 1
DROP INDEX new_name_idx;
CREATE TABLE metrics(time timestamptz, device_id int, v1 float, v2 float);
SELECT create_hypertable('metrics','time');
NOTICE:  adding not-null constraint to column "time"
  create_hypertable   
----------------------
 (8,public,metrics,t)
(1 row)

INSERT INTO metrics SELECT generate_series('2000-01-01'::timestamptz,'2000-01-10','1m'),1,0.25,0.75;
-- check expressions in view definition
CREATE VIEW cagg_expr
  WITH (timescaledb.continuous, timescaledb.materialized_only=true)
AS
SELECT
  time_bucket('1d', time) AS time,
  'Const'::text AS Const,
  4.3::numeric AS "numeric",
  first(metrics,time),
  CASE WHEN true THEN 'foo' ELSE 'bar' END,
  COALESCE(NULL,'coalesce'),
  avg(v1) + avg(v2) AS avg1,
  avg(v1+v2) AS avg2
FROM metrics
GROUP BY 1;
NOTICE:  adding index _materialized_hypertable_9_const_time_idx ON _timescaledb_internal._materialized_hypertable_9 USING BTREE(const, time)
NOTICE:  adding index _materialized_hypertable_9_numeric_time_idx ON _timescaledb_internal._materialized_hypertable_9 USING BTREE(numeric, time)
NOTICE:  adding index _materialized_hypertable_9_case_time_idx ON _timescaledb_internal._materialized_hypertable_9 USING BTREE(case, time)
NOTICE:  adding index _materialized_hypertable_9_coalesce_time_idx ON _timescaledb_internal._materialized_hypertable_9 USING BTREE(coalesce, time)
SET timescaledb.current_timestamp_mock = '2000-01-10';
REFRESH MATERIALIZED VIEW cagg_expr;
LOG:  materializing continuous aggregate public.cagg_expr: nothing to invalidate, new range up to Fri Jan 07 16:00:00 2000 PST
SELECT * FROM cagg_expr ORDER BY time LIMIT 5;
             time             | const | numeric |                    first                     | case | coalesce | avg1 | avg2 
------------------------------+-------+---------+----------------------------------------------+------+----------+------+------
 Fri Dec 31 16:00:00 1999 PST | Const |     4.3 | ("Sat Jan 01 00:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Sat Jan 01 16:00:00 2000 PST | Const |     4.3 | ("Sat Jan 01 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Sun Jan 02 16:00:00 2000 PST | Const |     4.3 | ("Sun Jan 02 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Mon Jan 03 16:00:00 2000 PST | Const |     4.3 | ("Mon Jan 03 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Tue Jan 04 16:00:00 2000 PST | Const |     4.3 | ("Tue Jan 04 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
(5 rows)

--
-- cascade_to_materialization = false tests
--
DROP TABLE IF EXISTS drop_chunks_table CASCADE;
NOTICE:  table "drop_chunks_table" does not exist, skipping
DROP TABLE IF EXISTS drop_chunks_table_u CASCADE;
NOTICE:  drop cascades to 2 other objects
NOTICE:  drop cascades to table _timescaledb_internal._hyper_7_9_chunk
CREATE TABLE drop_chunks_table(time BIGINT, data INTEGER);
SELECT hypertable_id AS drop_chunks_table_nid
    FROM create_hypertable('drop_chunks_table', 'time', chunk_time_interval => 10) \gset
NOTICE:  adding not-null constraint to column "time"
CREATE OR REPLACE FUNCTION integer_now_test2() returns bigint LANGUAGE SQL STABLE as $$ SELECT coalesce(max(time), bigint '0') FROM drop_chunks_table $$;
SELECT set_integer_now_func('drop_chunks_table', 'integer_now_test2');
 set_integer_now_func 
----------------------
 
(1 row)

CREATE VIEW drop_chunks_view
  WITH (
    timescaledb.continuous,
    timescaledb.materialized_only=true,
    timescaledb.refresh_interval='72 hours',
    timescaledb.refresh_lag = '-5',
    timescaledb.max_interval_per_job=10
  )
AS SELECT time_bucket('5', time), max(data)
    FROM drop_chunks_table
    GROUP BY 1;
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(0, 20) AS i;
\set ON_ERROR_STOP 0
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => 13, cascade_to_materializations => false);
ERROR:  older_than must be greater than the timescaledb.ignore_invalidation_older_than parameter of public.drop_chunks_view
ALTER VIEW drop_chunks_view SET (timescaledb.ignore_invalidation_older_than = 9);
-- 9 is too small (less than timescaledb.ignore_invalidation_older_than)
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-8), cascade_to_materializations => false);
ERROR:  older_than must be greater than the timescaledb.ignore_invalidation_older_than parameter of public.drop_chunks_view
-- 10 works but we don't have the completion threshold far enough along
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
ERROR:  the continuous aggregate public.drop_chunks_view is too far behind
\set ON_ERROR_STOP 1
REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  new materialization range for public.drop_chunks_table (time column time) larger than allowed in one run, truncating 25 to 10
LOG:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 10
WARNING:  REFRESH did not materialize the entire range since it was limited by the max_interval_per_job setting
\set ON_ERROR_STOP 0
--still too far behind
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
ERROR:  the continuous aggregate public.drop_chunks_view is too far behind
\set ON_ERROR_STOP 1
REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  new materialization range for public.drop_chunks_table (time column time) larger than allowed in one run, truncating 25 to 20
LOG:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 20
WARNING:  REFRESH did not materialize the entire range since it was limited by the max_interval_per_job setting
REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 25
--now, this works
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
LOG:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, no new range
LOG:  materializing continuous aggregate public.drop_chunks_view: no new range to materialize or invalidations found, exiting early
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_10_13_chunk
(1 row)

\set ON_ERROR_STOP 0
--must have older_than set and no newer than
SELECT drop_chunks(table_name => 'drop_chunks_table', cascade_to_materializations => false);
ERROR:  older_than and newer_than timestamps provided to drop_chunks cannot both be NULL
SELECT drop_chunks(table_name => 'drop_chunks_table', newer_than=>10, cascade_to_materializations => false);
ERROR:  cannot use newer_than parameter to drop_chunks with cascade_to_materializations
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => 20, newer_than=>10, cascade_to_materializations => false);
ERROR:  cannot use newer_than parameter to drop_chunks with cascade_to_materializations
\set ON_ERROR_STOP 1
--test materialization of invalidation before drop
SELECT * FROM drop_chunks_table ORDER BY time ASC limit 1;
 time | data 
------+------
   10 |   10
(1 row)

INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(20, 35) AS i;
REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  new materialization range for public.drop_chunks_table (time column time) larger than allowed in one run, truncating 40 to 30
LOG:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, new range up to 30
WARNING:  REFRESH did not materialize the entire range since it was limited by the max_interval_per_job setting
REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 40
--this is invalidated but beyond ignore_invalidation_threshold so will never be seen (current time is 29)
INSERT INTO drop_chunks_table SELECT i, 100 FROM generate_series(10, 19) AS i;
--this will be seen after the drop its within the invalidation window and will be dropped
INSERT INTO drop_chunks_table VALUES (26, 100);
--this will not be processed by the drop since chunk 30-39 is not dropped but will be seen after refresh
--shows that the drop doesn't do more work than necessary
INSERT INTO drop_chunks_table VALUES (31, 200);
--move the time up to 39
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(35, 39) AS i;
--the invalidation on 25 not yet seen
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          35 |  35
          30 |  34
          25 |  29
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(8 rows)

--dropping tables will cause the invalidation to be processed
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
LOG:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_10_14_chunk
 _timescaledb_internal._hyper_10_15_chunk
(2 rows)

--new values on 25 now seen in view
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          35 |  35
          30 |  34
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(8 rows)

--earliest datapoint now in table
SELECT * FROM drop_chunks_table ORDER BY time ASC limit 1;
 time | data 
------+------
   30 |   30
(1 row)

--we see the chunks row with the dropped flags set;
SELECT * FROM _timescaledb_catalog.chunk where dropped;
 id | hypertable_id |      schema_name      |     table_name     | compressed_chunk_id | dropped 
----+---------------+-----------------------+--------------------+---------------------+---------
 13 |            10 | _timescaledb_internal | _hyper_10_13_chunk |                     | t
 14 |            10 | _timescaledb_internal | _hyper_10_14_chunk |                     | t
 15 |            10 | _timescaledb_internal | _hyper_10_15_chunk |                     | t
(3 rows)

--still see data in the view
SELECT * FROM drop_chunks_view WHERE time_bucket < (integer_now_test2()-9) ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(6 rows)

--no data but covers dropped chunks
SELECT * FROM drop_chunks_table WHERE time < (integer_now_test2()-9) ORDER BY time DESC;
 time | data 
------+------
(0 rows)

--recreate the dropped chunk
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(0, 20) AS i;
--see data from recreated region
SELECT * FROM drop_chunks_table WHERE time < (integer_now_test2()-9) ORDER BY time DESC;
 time | data 
------+------
   20 |   20
   19 |   19
   18 |   18
   17 |   17
   16 |   16
   15 |   15
   14 |   14
   13 |   13
   12 |   12
   11 |   11
   10 |   10
    9 |    9
    8 |    8
    7 |    7
    6 |    6
    5 |    5
    4 |    4
    3 |    3
    2 |    2
    1 |    1
    0 |    0
(21 rows)

REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
WARNING:  REFRESH did not materialize the entire range since it was limited by the max_interval_per_job setting
REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  new materialization range not found for public.drop_chunks_table (time column time): not enough new data past completion threshold of 40 as of 39
LOG:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, no new range
LOG:  materializing continuous aggregate public.drop_chunks_view: no new range to materialize or invalidations found, exiting early
--change to bucket 31 also seen
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          35 |  39
          30 | 200
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(8 rows)

--show that the invalidation processed during drop aren't limited by max_interval_per_job
ALTER VIEW drop_chunks_view SET (timescaledb.max_interval_per_job = 5);
INSERT INTO drop_chunks_table SELECT i, 300+i FROM generate_series(31, 39) AS i;
--move the time up to 49
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(40, 49) AS i;
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          35 |  39
          30 | 200
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(8 rows)

--should see multiple rounds of invalidation in the log messages
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
LOG:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
LOG:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
LOG:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, no new range
LOG:  materializing continuous aggregate public.drop_chunks_view: no new range to materialize or invalidations found, exiting early
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_10_17_chunk
 _timescaledb_internal._hyper_10_13_chunk
 _timescaledb_internal._hyper_10_14_chunk
 _timescaledb_internal._hyper_10_15_chunk
(4 rows)

--see both 30 and 35 updated
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          35 | 339
          30 | 334
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(8 rows)

--test splitting one range for invalidation in drop_chunks and then later
ALTER VIEW drop_chunks_view SET (timescaledb.max_interval_per_job = 100);
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(50,55) AS i;
REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  materializing continuous aggregate public.drop_chunks_view: nothing to invalidate, new range up to 60
--one command and thus one range that spans 46 (which will be processed by drop_chunks) and (51 which won't, but will be later)
INSERT INTO drop_chunks_table VALUES (46, 400), (51, 500);
INSERT INTO drop_chunks_table SELECT i, i FROM generate_series(56,59) AS i;
--neither invalidation is seen
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          55 |  55
          50 |  54
          45 |  49
          40 |  44
          35 | 339
          30 | 334
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(12 rows)

SELECT drop_chunks(table_name => 'drop_chunks_table', older_than => (integer_now_test2()-9), cascade_to_materializations => false);
NOTICE:  making sure all invalidations for public.drop_chunks_view have been processed prior to dropping chunks
LOG:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_10_18_chunk
(1 row)

--the change in bucket 45 but not 50 is seen
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          55 |  55
          50 |  54
          45 | 400
          40 |  44
          35 | 339
          30 | 334
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(12 rows)

REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  new materialization range not found for public.drop_chunks_table (time column time): not enough new data past completion threshold of 60 as of 59
LOG:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
--the change in bucket 50 is seen
SELECT * FROM drop_chunks_view ORDER BY time_bucket DESC;
 time_bucket | max 
-------------+-----
          55 |  59
          50 | 500
          45 | 400
          40 |  44
          35 | 339
          30 | 334
          25 | 100
          20 |  24
          15 |  19
          10 |  14
           5 |   9
           0 |   4
(12 rows)

--no data but covers dropped chunks
SELECT * FROM drop_chunks_table WHERE time < (integer_now_test2()-9) ORDER BY time DESC;
 time | data 
------+------
(0 rows)

SELECT set_chunk_time_interval('drop_chunks_table', 1000);
 set_chunk_time_interval 
-------------------------
 
(1 row)

SELECT chunk_table, ranges FROM chunk_relation_size('drop_chunks_table');
               chunk_table                |   ranges    
------------------------------------------+-------------
 _timescaledb_internal._hyper_10_19_chunk | {"[50,60)"}
(1 row)

--recreate the dropped chunk
INSERT INTO drop_chunks_table VALUES (20, 20);
--now sees the re-entered data
SELECT * FROM drop_chunks_table WHERE time < (integer_now_test2()-9) ORDER BY time DESC;
 time | data 
------+------
   20 |   20
(1 row)

--should show chunk with old name and old ranges
SELECT chunk_table, ranges FROM chunk_relation_size('drop_chunks_table');
               chunk_table                |   ranges    
------------------------------------------+-------------
 _timescaledb_internal._hyper_10_15_chunk | {"[20,30)"}
 _timescaledb_internal._hyper_10_19_chunk | {"[50,60)"}
(2 rows)

-- TEST drop_chunks with cascade_to_materialization set to true (github 1644)
-- This checks if chunks from mat. hypertable are actually dropped
-- and deletes data from chunks that cannot be dropped from that mat. hypertable.
SELECT format('%s.%s', schema_name, table_name) AS drop_chunks_mat_tablen,
        schema_name AS drop_chunks_mat_schema,
        table_name AS drop_chunks_mat_table_name
    FROM _timescaledb_catalog.hypertable, _timescaledb_catalog.continuous_agg
    WHERE _timescaledb_catalog.continuous_agg.raw_hypertable_id = :drop_chunks_table_nid
        AND _timescaledb_catalog.hypertable.id = _timescaledb_catalog.continuous_agg.mat_hypertable_id \gset
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than=>integer_now_test2() + 200, cascade_to_materializations => true);
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_10_19_chunk
 _timescaledb_internal._hyper_10_15_chunk
(2 rows)

SELECT count(c) FROM show_chunks('drop_chunks_table') AS c;
 count 
-------
     0
(1 row)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_tablen') AS c;
 count 
-------
     0
(1 row)

SELECT set_chunk_time_interval('drop_chunks_table', 10);
 set_chunk_time_interval 
-------------------------
 
(1 row)

SELECT set_chunk_time_interval(:'drop_chunks_mat_tablen', 20);
 set_chunk_time_interval 
-------------------------
 
(1 row)

INSERT INTO drop_chunks_table SELECT generate_series(1,35), 100;
update drop_chunks_table set data = 250 where time = 25;
update drop_chunks_table set data = 290 where time = 29;
REFRESH materialized view drop_chunks_view;
LOG:  new materialization range not found for public.drop_chunks_table (time column time): not enough new data past completion threshold of 60 as of 35
LOG:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
REFRESH materialized view drop_chunks_view;
LOG:  new materialization range not found for public.drop_chunks_table (time column time): not enough new data past completion threshold of 60 as of 35
LOG:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
--now we have chunks in both mat and raw hypertables
select * from drop_chunks_view order by 1;
 time_bucket | max 
-------------+-----
           0 | 100
           5 | 100
          10 | 100
          15 | 100
          20 | 100
          25 | 290
          30 | 100
          35 | 100
(8 rows)

SELECT chunk_table, ranges FROM chunk_relation_size('drop_chunks_table')
ORDER BY ranges;
               chunk_table                |   ranges    
------------------------------------------+-------------
 _timescaledb_internal._hyper_10_13_chunk | {"[0,10)"}
 _timescaledb_internal._hyper_10_14_chunk | {"[10,20)"}
 _timescaledb_internal._hyper_10_20_chunk | {"[20,30)"}
 _timescaledb_internal._hyper_10_17_chunk | {"[30,40)"}
(4 rows)

SELECT chunk_table, ranges FROM chunk_relation_size(:'drop_chunks_mat_tablen')
ORDER BY ranges;
               chunk_table                |   ranges    
------------------------------------------+-------------
 _timescaledb_internal._hyper_11_21_chunk | {"[0,20)"}
 _timescaledb_internal._hyper_11_22_chunk | {"[20,40)"}
(2 rows)

--1 chunk from the mat. hypertable will be dropped and the other will
--need deletes when the chunks from the raw hypertable are dropped.
SELECT drop_chunks(table_name => 'drop_chunks_table', older_than=>integer_now_test2() - 4 , cascade_to_materializations => true);
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_10_13_chunk
 _timescaledb_internal._hyper_10_14_chunk
 _timescaledb_internal._hyper_10_20_chunk
(3 rows)

SELECT * from drop_chunks_view ORDER BY 1;
 time_bucket | max 
-------------+-----
          30 | 100
          35 | 100
(2 rows)

SELECT count(c) FROM show_chunks(:'drop_chunks_mat_tablen') AS c;
 count 
-------
     1
(1 row)

SELECT chunk_table, ranges FROM chunk_relation_size(:'drop_chunks_mat_tablen')
ORDER BY ranges;
               chunk_table                |   ranges    
------------------------------------------+-------------
 _timescaledb_internal._hyper_11_22_chunk | {"[20,40)"}
(1 row)

-- TEST drop chunks from continuous aggregates by specifying view name
SELECT drop_chunks(
    table_name => 'drop_chunks_view',
    newer_than => -20,
    verbose => true);
INFO:  dropping chunk _timescaledb_internal._hyper_11_22_chunk
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_11_22_chunk
(1 row)

--can also drop chunks by specifying materialized hypertable name
INSERT INTO drop_chunks_table SELECT generate_series(45, 55), 500;
REFRESH MATERIALIZED VIEW drop_chunks_view;
LOG:  new materialization range not found for public.drop_chunks_table (time column time): not enough new data past completion threshold of 60 as of 55
LOG:  materializing continuous aggregate public.drop_chunks_view: processing invalidations, no new range
SELECT chunk_table, ranges FROM chunk_relation_size(:'drop_chunks_mat_tablen');
               chunk_table                |   ranges    
------------------------------------------+-------------
 _timescaledb_internal._hyper_11_24_chunk | {"[40,60)"}
(1 row)

\set ON_ERROR_STOP 0
SELECT drop_chunks(
    table_name => :'drop_chunks_mat_table_name',
    older_than => 60,
    verbose => true);
ERROR:  "_materialized_hypertable_11" is not a hypertable or a continuous aggregate view
\set ON_ERROR_STOP 1
SELECT drop_chunks(
    schema_name => :'drop_chunks_mat_schema',
    table_name => :'drop_chunks_mat_table_name',
    older_than => 60,
    verbose => true);
INFO:  dropping chunk _timescaledb_internal._hyper_11_24_chunk
               drop_chunks                
------------------------------------------
 _timescaledb_internal._hyper_11_24_chunk
(1 row)

