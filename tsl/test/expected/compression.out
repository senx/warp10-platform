-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
SET timescaledb.enable_transparent_decompression to OFF;
\ir include/rand_generator.sql
-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
--------------------------
-- cheap rand generator --
--------------------------
create table rand_minstd_state(i bigint);
create function rand_minstd_advance(bigint) returns bigint
language sql immutable as
$$
	select (16807 * $1) % 2147483647
$$;
create function gen_rand_minstd() returns bigint
language sql security definer as
$$
	update rand_minstd_state set i = rand_minstd_advance(i) returning i
$$;
-- seed the random num generator
insert into rand_minstd_state values (321);
--test_collation ---
--basic test with count
create table foo (a integer, b integer, c integer, d integer);
select table_name from create_hypertable('foo', 'a', chunk_time_interval=> 10);
NOTICE:  adding not-null constraint to column "a"
 table_name 
------------
 foo
(1 row)

create unique index foo_uniq ON foo (a, b);
--note that the "d" order by column is all NULL
insert into foo values( 3 , 16 , 20, NULL);
insert into foo values( 10 , 10 , 20, NULL);
insert into foo values( 20 , 11 , 20, NULL);
insert into foo values( 30 , 12 , 20, NULL);
alter table foo set (timescaledb.compress, timescaledb.compress_segmentby = 'a,b', timescaledb.compress_orderby = 'c desc, d asc nulls last');
NOTICE:  adding index _compressed_hypertable_2_a__ts_meta_sequence_num_idx ON _timescaledb_internal._compressed_hypertable_2 USING BTREE(a, _ts_meta_sequence_num)
NOTICE:  adding index _compressed_hypertable_2_b__ts_meta_sequence_num_idx ON _timescaledb_internal._compressed_hypertable_2 USING BTREE(b, _ts_meta_sequence_num)
--test self-refencing updates
SET timescaledb.enable_transparent_decompression to ON;
update foo set c = 40
where  a = (SELECT max(a) FROM foo);
SET timescaledb.enable_transparent_decompression to OFF;
select id, schema_name, table_name, compressed, compressed_hypertable_id from
_timescaledb_catalog.hypertable order by id;
 id |      schema_name      |        table_name        | compressed | compressed_hypertable_id 
----+-----------------------+--------------------------+------------+--------------------------
  1 | public                | foo                      | f          |                        2
  2 | _timescaledb_internal | _compressed_hypertable_2 | t          |                         
(2 rows)

select * from _timescaledb_catalog.hypertable_compression order by hypertable_id, attname;
 hypertable_id | attname | compression_algorithm_id | segmentby_column_index | orderby_column_index | orderby_asc | orderby_nullsfirst 
---------------+---------+--------------------------+------------------------+----------------------+-------------+--------------------
             1 | a       |                        0 |                      1 |                      |             | 
             1 | b       |                        0 |                      2 |                      |             | 
             1 | c       |                        4 |                        |                    1 | f           | t
             1 | d       |                        4 |                        |                    2 | t           | f
(4 rows)

-- TEST2 compress-chunk for the chunks created earlier --
select compress_chunk( '_timescaledb_internal._hyper_1_2_chunk');
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_2_chunk
(1 row)

select tgname , tgtype, tgenabled , relname
from pg_trigger t, pg_class rel
where t.tgrelid = rel.oid and rel.relname like '_hyper_1_2_chunk' order by tgname;
             tgname              | tgtype | tgenabled |     relname      
---------------------------------+--------+-----------+------------------
 compressed_chunk_insert_blocker |      7 | O         | _hyper_1_2_chunk
(1 row)

\x
select * from timescaledb_information.compressed_chunk_stats
order by chunk_name limit 2;
-[ RECORD 1 ]------------+---------------------------------------
hypertable_name          | foo
chunk_name               | _timescaledb_internal._hyper_1_1_chunk
compression_status       | Uncompressed
uncompressed_heap_bytes  | 
uncompressed_index_bytes | 
uncompressed_toast_bytes | 
uncompressed_total_bytes | 
compressed_heap_bytes    | 
compressed_index_bytes   | 
compressed_toast_bytes   | 
compressed_total_bytes   | 
-[ RECORD 2 ]------------+---------------------------------------
hypertable_name          | foo
chunk_name               | _timescaledb_internal._hyper_1_2_chunk
compression_status       | Compressed
uncompressed_heap_bytes  | 8192 bytes
uncompressed_index_bytes | 32 kB
uncompressed_toast_bytes | 0 bytes
uncompressed_total_bytes | 40 kB
compressed_heap_bytes    | 8192 bytes
compressed_index_bytes   | 32 kB
compressed_toast_bytes   | 8192 bytes
compressed_total_bytes   | 48 kB

\x
select compress_chunk( '_timescaledb_internal._hyper_1_1_chunk');
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
(1 row)

\x
select * from _timescaledb_catalog.compression_chunk_size
order by chunk_id;
-[ RECORD 1 ]-----------+------
chunk_id                | 1
compressed_chunk_id     | 6
uncompressed_heap_size  | 8192
uncompressed_toast_size | 0
uncompressed_index_size | 32768
compressed_heap_size    | 8192
compressed_toast_size   | 8192
compressed_index_size   | 32768
-[ RECORD 2 ]-----------+------
chunk_id                | 2
compressed_chunk_id     | 5
uncompressed_heap_size  | 8192
uncompressed_toast_size | 0
uncompressed_index_size | 32768
compressed_heap_size    | 8192
compressed_toast_size   | 8192
compressed_index_size   | 32768

\x
select  ch1.id, ch1.schema_name, ch1.table_name ,  ch2.table_name as compress_table
from
_timescaledb_catalog.chunk ch1, _timescaledb_catalog.chunk ch2
where ch1.compressed_chunk_id = ch2.id;
 id |      schema_name      |    table_name    |      compress_table      
----+-----------------------+------------------+--------------------------
  2 | _timescaledb_internal | _hyper_1_2_chunk | compress_hyper_2_5_chunk
  1 | _timescaledb_internal | _hyper_1_1_chunk | compress_hyper_2_6_chunk
(2 rows)

\set ON_ERROR_STOP 0
--cannot recompress the chunk the second time around
select compress_chunk( '_timescaledb_internal._hyper_1_2_chunk');
ERROR:  chunk "_hyper_1_2_chunk" is already compressed
--TEST2a try DML on a compressed chunk
insert into foo values( 11 , 10 , 20, 120);
ERROR:  insert/update/delete not permitted on chunk "_hyper_1_2_chunk"
update foo set b =20 where a = 10;
ERROR:  cannot update/delete rows from chunk "_hyper_1_2_chunk" as it is compressed
delete from foo where a = 10;
ERROR:  cannot update/delete rows from chunk "_hyper_1_2_chunk" as it is compressed
--TEST2b try complex DML on compressed chunk
create table foo_join ( a integer, newval integer);
select table_name from create_hypertable('foo_join', 'a', chunk_time_interval=> 10);
NOTICE:  adding not-null constraint to column "a"
 table_name 
------------
 foo_join
(1 row)

insert into foo_join select generate_series(0,40, 10), 111;
create table foo_join2 ( a integer, newval integer);
select table_name from create_hypertable('foo_join2', 'a', chunk_time_interval=> 10);
NOTICE:  adding not-null constraint to column "a"
 table_name 
------------
 foo_join2
(1 row)

insert into foo_join select generate_series(0,40, 10), 222;
update foo
set b = newval
from foo_join where foo.a = foo_join.a;
ERROR:  cannot update/delete rows from chunk "_hyper_1_1_chunk" as it is compressed
update foo
set b = newval
from foo_join where foo.a = foo_join.a and foo_join.a > 10;
ERROR:  cannot update/delete rows from chunk "_hyper_1_1_chunk" as it is compressed
--here the chunk gets excluded , so succeeds --
update foo
set b = newval
from foo_join where foo.a = foo_join.a and foo.a > 20;
update foo
set b = (select f1.newval from foo_join f1 left join lateral (select newval as newval2 from  foo_join2 f2 where f1.a= f2.a ) subq on true limit 1);
ERROR:  cannot update/delete rows from chunk "_hyper_1_1_chunk" as it is compressed
--upsert test --
insert into foo values(10, 12, 12, 12)
on conflict( a, b)
do update set b = excluded.b;
ERROR:  insert/update/delete not permitted on chunk "_hyper_1_2_chunk"
--TEST2c dml directly on the chunk NOTE update/deletes don't get blocked (TODO)
insert into _timescaledb_internal._hyper_1_2_chunk values(10, 12, 12, 12);
ERROR:  insert/update/delete not permitted on chunk "_hyper_1_2_chunk"
update _timescaledb_internal._hyper_1_2_chunk
set b = 12;
delete from _timescaledb_internal._hyper_1_2_chunk;
--TEST2d decompress the chunk and try DML
select decompress_chunk( '_timescaledb_internal._hyper_1_2_chunk');
            decompress_chunk            
----------------------------------------
 _timescaledb_internal._hyper_1_2_chunk
(1 row)

insert into foo values( 11 , 10 , 20, 120);
update foo set b =20 where a = 10;
select * from _timescaledb_internal._hyper_1_2_chunk order by a;
 a  | b  | c  |  d  
----+----+----+-----
 10 | 20 | 20 |    
 11 | 10 | 20 | 120
(2 rows)

delete from foo where a = 10;
select * from _timescaledb_internal._hyper_1_2_chunk order by a;
 a  | b  | c  |  d  
----+----+----+-----
 11 | 10 | 20 | 120
(1 row)

-- TEST3 check if compress data from views is accurate
CREATE TABLE conditions (
      time        TIMESTAMPTZ       NOT NULL,
      location    TEXT              NOT NULL,
      location2    char(10)              NOT NULL,
      temperature DOUBLE PRECISION  NULL,
      humidity    DOUBLE PRECISION  NULL
    );
select create_hypertable( 'conditions', 'time', chunk_time_interval=> '31days'::interval);
    create_hypertable    
-------------------------
 (5,public,conditions,t)
(1 row)

alter table conditions set (timescaledb.compress, timescaledb.compress_segmentby = 'location', timescaledb.compress_orderby = 'time');
NOTICE:  adding index _compressed_hypertable_6_location__ts_meta_sequence_num_idx ON _timescaledb_internal._compressed_hypertable_6 USING BTREE(location, _ts_meta_sequence_num)
insert into conditions
select generate_series('2018-12-01 00:00'::timestamp, '2018-12-31 00:00'::timestamp, '1 day'), 'POR', 'klick', 55, 75;
insert into conditions
select generate_series('2018-12-01 00:00'::timestamp, '2018-12-31 00:00'::timestamp, '1 day'), 'NYC', 'klick', 55, 75;
select hypertable_id, attname, compression_algorithm_id , al.name
from _timescaledb_catalog.hypertable_compression hc,
     _timescaledb_catalog.hypertable ht,
      _timescaledb_catalog.compression_algorithm al
where ht.id = hc.hypertable_id and ht.table_name like 'conditions' and al.id = hc.compression_algorithm_id
ORDER BY hypertable_id, attname;
 hypertable_id |   attname   | compression_algorithm_id |               name               
---------------+-------------+--------------------------+----------------------------------
             5 | humidity    |                        3 | COMPRESSION_ALGORITHM_GORILLA
             5 | location    |                        0 | COMPRESSION_ALGORITHM_NONE
             5 | location2   |                        2 | COMPRESSION_ALGORITHM_DICTIONARY
             5 | temperature |                        3 | COMPRESSION_ALGORITHM_GORILLA
             5 | time        |                        4 | COMPRESSION_ALGORITHM_DELTADELTA
(5 rows)

select attname, attstorage, typname from pg_attribute at, pg_class cl , pg_type ty
where cl.oid = at.attrelid and  at.attnum > 0
and cl.relname = '_compressed_hypertable_4'
and atttypid = ty.oid
order by at.attnum;
 attname | attstorage | typname 
---------+------------+---------
(0 rows)

SELECT ch1.schema_name|| '.' || ch1.table_name as "CHUNK_NAME", ch1.id "CHUNK_ID"
FROM _timescaledb_catalog.chunk ch1, _timescaledb_catalog.hypertable ht where ch1.hypertable_id = ht.id and ht.table_name like 'conditions'
ORDER BY ch1.id
LIMIT 1 \gset
SELECT count(*) from :CHUNK_NAME;
 count 
-------
    42
(1 row)

SELECT count(*) as "ORIGINAL_CHUNK_COUNT" from :CHUNK_NAME \gset
select tableoid::regclass, count(*) from conditions group by tableoid order by tableoid;
                tableoid                 | count 
-----------------------------------------+-------
 _timescaledb_internal._hyper_5_12_chunk |    42
 _timescaledb_internal._hyper_5_13_chunk |    20
(2 rows)

select  compress_chunk(ch1.schema_name|| '.' || ch1.table_name)
FROM _timescaledb_catalog.chunk ch1, _timescaledb_catalog.hypertable ht where ch1.hypertable_id = ht.id and ht.table_name like 'conditions' ORDER BY ch1.id limit 1;
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_5_12_chunk
(1 row)

--test that only one chunk was affected
--note tables with 0 rows will not show up in here.
select tableoid::regclass, count(*) from conditions group by tableoid order by tableoid;
                tableoid                 | count 
-----------------------------------------+-------
 _timescaledb_internal._hyper_5_13_chunk |    20
(1 row)

select  compress_chunk(ch1.schema_name|| '.' || ch1.table_name)
FROM _timescaledb_catalog.chunk ch1, _timescaledb_catalog.hypertable ht where ch1.hypertable_id = ht.id and ht.table_name like 'conditions' and ch1.compressed_chunk_id IS NULL;
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_5_13_chunk
(1 row)

select tableoid::regclass, count(*) from conditions group by tableoid order by tableoid;
 tableoid | count 
----------+-------
(0 rows)

select  compressed.schema_name|| '.' || compressed.table_name as "COMPRESSED_CHUNK_NAME"
from _timescaledb_catalog.chunk uncompressed, _timescaledb_catalog.chunk compressed
where uncompressed.compressed_chunk_id = compressed.id AND uncompressed.id = :'CHUNK_ID' \gset
SELECT count(*) from :CHUNK_NAME;
 count 
-------
     0
(1 row)

SELECT count(*) from :COMPRESSED_CHUNK_NAME;
 count 
-------
     2
(1 row)

SELECT sum(_ts_meta_count) from :COMPRESSED_CHUNK_NAME;
 sum 
-----
  42
(1 row)

SELECT _ts_meta_sequence_num from :COMPRESSED_CHUNK_NAME;
 _ts_meta_sequence_num 
-----------------------
                    10
                    20
(2 rows)

\x
select * from timescaledb_information.compressed_chunk_stats
where hypertable_name::text like 'conditions'
order by hypertable_name, chunk_name;
-[ RECORD 1 ]------------+----------------------------------------
hypertable_name          | conditions
chunk_name               | _timescaledb_internal._hyper_5_12_chunk
compression_status       | Compressed
uncompressed_heap_bytes  | 8192 bytes
uncompressed_index_bytes | 16 kB
uncompressed_toast_bytes | 8192 bytes
uncompressed_total_bytes | 32 kB
compressed_heap_bytes    | 8192 bytes
compressed_index_bytes   | 16 kB
compressed_toast_bytes   | 8192 bytes
compressed_total_bytes   | 32 kB
-[ RECORD 2 ]------------+----------------------------------------
hypertable_name          | conditions
chunk_name               | _timescaledb_internal._hyper_5_13_chunk
compression_status       | Compressed
uncompressed_heap_bytes  | 8192 bytes
uncompressed_index_bytes | 16 kB
uncompressed_toast_bytes | 8192 bytes
uncompressed_total_bytes | 32 kB
compressed_heap_bytes    | 8192 bytes
compressed_index_bytes   | 16 kB
compressed_toast_bytes   | 8192 bytes
compressed_total_bytes   | 32 kB

select * from timescaledb_information.compressed_hypertable_stats
order by hypertable_name;
-[ RECORD 1 ]------------+-----------
hypertable_name          | foo
total_chunks             | 4
number_compressed_chunks | 1
uncompressed_heap_bytes  | 8192 bytes
uncompressed_index_bytes | 32 kB
uncompressed_toast_bytes | 0 bytes
uncompressed_total_bytes | 40 kB
compressed_heap_bytes    | 8192 bytes
compressed_index_bytes   | 32 kB
compressed_toast_bytes   | 8192 bytes
compressed_total_bytes   | 48 kB
-[ RECORD 2 ]------------+-----------
hypertable_name          | conditions
total_chunks             | 2
number_compressed_chunks | 2
uncompressed_heap_bytes  | 16 kB
uncompressed_index_bytes | 32 kB
uncompressed_toast_bytes | 16 kB
uncompressed_total_bytes | 64 kB
compressed_heap_bytes    | 16 kB
compressed_index_bytes   | 32 kB
compressed_toast_bytes   | 16 kB
compressed_total_bytes   | 64 kB

vacuum full foo;
vacuum full conditions;
-- After vacuum, table_bytes is 0, but any associated index/toast storage is not
-- completely reclaimed. Sets it at 8K (page size). So a chunk which has
-- been compressed still incurs an overhead of n * 8KB (for every index + toast table) storage on the original uncompressed chunk.
select * from timescaledb_information.hypertable
where table_name like 'foo' or table_name like 'conditions'
order by table_name;
-[ RECORD 1 ]--+------------------
table_schema   | public
table_name     | conditions
table_owner    | default_perm_user
num_dimensions | 1
num_chunks     | 2
table_size     | 16 kB
index_size     | 48 kB
toast_size     | 32 kB
total_size     | 96 kB
-[ RECORD 2 ]--+------------------
table_schema   | public
table_name     | foo
table_owner    | default_perm_user
num_dimensions | 1
num_chunks     | 4
table_size     | 32 kB
index_size     | 144 kB
toast_size     | 8192 bytes
total_size     | 184 kB

\x
select decompress_chunk(ch1.schema_name|| '.' || ch1.table_name)
FROM _timescaledb_catalog.chunk ch1, _timescaledb_catalog.hypertable ht where ch1.hypertable_id = ht.id and ht.table_name like 'conditions';
            decompress_chunk             
-----------------------------------------
 _timescaledb_internal._hyper_5_13_chunk
 _timescaledb_internal._hyper_5_12_chunk
(2 rows)

SELECT count(*), count(*) = :'ORIGINAL_CHUNK_COUNT' from :CHUNK_NAME;
 count | ?column? 
-------+----------
    42 | t
(1 row)

--check that the compressed chunk is dropped
\set ON_ERROR_STOP 0
SELECT count(*) from :COMPRESSED_CHUNK_NAME;
ERROR:  relation "_timescaledb_internal.compress_hyper_6_14_chunk" does not exist at character 22
\set ON_ERROR_STOP 1
--size information is gone too
select count(*)
FROM _timescaledb_catalog.chunk ch1, _timescaledb_catalog.hypertable ht,
_timescaledb_catalog.compression_chunk_size map
where ch1.hypertable_id = ht.id and ht.table_name like 'conditions'
and map.chunk_id = ch1.id;
 count 
-------
     0
(1 row)

--make sure  compressed_chunk_id  is reset to NULL
select ch1.compressed_chunk_id IS NULL
FROM _timescaledb_catalog.chunk ch1, _timescaledb_catalog.hypertable ht where ch1.hypertable_id = ht.id and ht.table_name like 'conditions';
 ?column? 
----------
 t
 t
(2 rows)

-- test plans get invalidated when chunks get compressed
SET timescaledb.enable_transparent_decompression TO ON;
CREATE TABLE plan_inval(time timestamptz, device_id int);
SELECT create_hypertable('plan_inval','time');
NOTICE:  adding not-null constraint to column "time"
    create_hypertable    
-------------------------
 (7,public,plan_inval,t)
(1 row)

ALTER TABLE plan_inval SET (timescaledb.compress,timescaledb.compress_orderby='time desc');
-- create 2 chunks
INSERT INTO plan_inval SELECT * FROM (VALUES ('2000-01-01'::timestamptz,1), ('2000-01-07'::timestamptz,1)) v(time,device_id);
SET max_parallel_workers_per_gather to 0;
PREPARE prep_plan AS SELECT count(*) FROM plan_inval;
EXECUTE prep_plan;
 count 
-------
     2
(1 row)

EXECUTE prep_plan;
 count 
-------
     2
(1 row)

EXECUTE prep_plan;
 count 
-------
     2
(1 row)

-- get name of first chunk
SELECT tableoid::regclass AS "CHUNK_NAME" FROM plan_inval ORDER BY time LIMIT 1
\gset
SELECT compress_chunk(:'CHUNK_NAME');
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_7_16_chunk
(1 row)

EXECUTE prep_plan;
 count 
-------
     2
(1 row)

EXPLAIN (COSTS OFF) EXECUTE prep_plan;
                           QUERY PLAN                           
----------------------------------------------------------------
 Aggregate
   ->  Append
         ->  Custom Scan (DecompressChunk) on _hyper_7_16_chunk
               ->  Seq Scan on compress_hyper_8_18_chunk
         ->  Seq Scan on _hyper_7_17_chunk
(5 rows)

CREATE TABLE test_collation (
      time      TIMESTAMPTZ       NOT NULL,
      device_id  TEXT   COLLATE "C"           NULL,
      device_id_2  TEXT  COLLATE "POSIX"           NULL,
      val_1 TEXT  COLLATE "C" NULL,
      val_2 TEXT COLLATE "POSIX"  NULL
    );
--we want all the data to go into 1 chunk. so use 1 year chunk interval
select create_hypertable( 'test_collation', 'time', chunk_time_interval=> '1 day'::interval);
      create_hypertable      
-----------------------------
 (9,public,test_collation,t)
(1 row)

\set ON_ERROR_STOP 0
--forbid setting collation in compression ORDER BY clause. (parse error is fine)
alter table test_collation set (timescaledb.compress, timescaledb.compress_segmentby='device_id, device_id_2', timescaledb.compress_orderby = 'val_1 COLLATE "POSIX", val2, time');
ERROR:  unable to parse timescaledb.compress_orderby option 'val_1 COLLATE "POSIX", val2, time'
\set ON_ERROR_STOP 1
alter table test_collation set (timescaledb.compress, timescaledb.compress_segmentby='device_id, device_id_2', timescaledb.compress_orderby = 'val_1, val_2, time');
NOTICE:  adding index _compressed_hypertable_10_device_id__ts_meta_sequence_num_idx ON _timescaledb_internal._compressed_hypertable_10 USING BTREE(device_id, _ts_meta_sequence_num)
NOTICE:  adding index _compressed_hypertable_10_device_id_2__ts_meta_sequence_num_idx ON _timescaledb_internal._compressed_hypertable_10 USING BTREE(device_id_2, _ts_meta_sequence_num)
insert into test_collation
select generate_series('2018-01-01 00:00'::timestamp, '2018-01-10 00:00'::timestamp, '2 hour'), 'device_1', 'device_3', gen_rand_minstd(), gen_rand_minstd();
insert into test_collation
select generate_series('2018-01-01 00:00'::timestamp, '2018-01-10 00:00'::timestamp, '2 hour'), 'device_2', 'device_4', gen_rand_minstd(), gen_rand_minstd();
insert into test_collation
select generate_series('2018-01-01 00:00'::timestamp, '2018-01-10 00:00'::timestamp, '2 hour'), NULL, 'device_5', gen_rand_minstd(), gen_rand_minstd();
--compress 2 chunks
SELECT compress_chunk(ch1.schema_name|| '.' || ch1.table_name)
FROM _timescaledb_catalog.chunk ch1, _timescaledb_catalog.hypertable ht where ch1.hypertable_id = ht.id
and ht.table_name like 'test_collation' ORDER BY ch1.id LIMIT 2;
             compress_chunk              
-----------------------------------------
 _timescaledb_internal._hyper_9_19_chunk
 _timescaledb_internal._hyper_9_20_chunk
(2 rows)

--segment bys are pushed down correctly
EXPLAIN (costs off) SELECT * FROM test_collation WHERE device_id < 'a';
                        QUERY PLAN                        
----------------------------------------------------------
 Append
   ->  Custom Scan (DecompressChunk) on _hyper_9_19_chunk
         ->  Seq Scan on compress_hyper_10_29_chunk
               Filter: (device_id < 'a'::text)
   ->  Custom Scan (DecompressChunk) on _hyper_9_20_chunk
         ->  Seq Scan on compress_hyper_10_30_chunk
               Filter: (device_id < 'a'::text)
   ->  Seq Scan on _hyper_9_21_chunk
         Filter: (device_id < 'a'::text)
   ->  Seq Scan on _hyper_9_22_chunk
         Filter: (device_id < 'a'::text)
   ->  Seq Scan on _hyper_9_23_chunk
         Filter: (device_id < 'a'::text)
   ->  Seq Scan on _hyper_9_24_chunk
         Filter: (device_id < 'a'::text)
   ->  Seq Scan on _hyper_9_25_chunk
         Filter: (device_id < 'a'::text)
   ->  Seq Scan on _hyper_9_26_chunk
         Filter: (device_id < 'a'::text)
   ->  Seq Scan on _hyper_9_27_chunk
         Filter: (device_id < 'a'::text)
   ->  Seq Scan on _hyper_9_28_chunk
         Filter: (device_id < 'a'::text)
(23 rows)

EXPLAIN (costs off) SELECT * FROM test_collation WHERE device_id < 'a' COLLATE "POSIX";
                          QUERY PLAN                           
---------------------------------------------------------------
 Append
   ->  Custom Scan (DecompressChunk) on _hyper_9_19_chunk
         ->  Seq Scan on compress_hyper_10_29_chunk
               Filter: (device_id < 'a'::text COLLATE "POSIX")
   ->  Custom Scan (DecompressChunk) on _hyper_9_20_chunk
         ->  Seq Scan on compress_hyper_10_30_chunk
               Filter: (device_id < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_21_chunk
         Filter: (device_id < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_22_chunk
         Filter: (device_id < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_23_chunk
         Filter: (device_id < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_24_chunk
         Filter: (device_id < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_25_chunk
         Filter: (device_id < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_26_chunk
         Filter: (device_id < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_27_chunk
         Filter: (device_id < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_28_chunk
         Filter: (device_id < 'a'::text COLLATE "POSIX")
(23 rows)

\set ON_ERROR_STOP 0
EXPLAIN (costs off) SELECT * FROM test_collation WHERE device_id COLLATE "POSIX" < device_id_2 COLLATE "C";
ERROR:  collation mismatch between explicit collations "POSIX" and "C" at character 96
SELECT device_id < device_id_2  FROM test_collation;
ERROR:  could not determine which collation to use for string comparison
\set ON_ERROR_STOP 1
--segment meta on order bys pushdown
--should work
EXPLAIN (costs off) SELECT * FROM test_collation WHERE val_1 < 'a';
                        QUERY PLAN                        
----------------------------------------------------------
 Append
   ->  Custom Scan (DecompressChunk) on _hyper_9_19_chunk
         Filter: (val_1 < 'a'::text)
         ->  Seq Scan on compress_hyper_10_29_chunk
               Filter: (_ts_meta_min_1 < 'a'::text)
   ->  Custom Scan (DecompressChunk) on _hyper_9_20_chunk
         Filter: (val_1 < 'a'::text)
         ->  Seq Scan on compress_hyper_10_30_chunk
               Filter: (_ts_meta_min_1 < 'a'::text)
   ->  Seq Scan on _hyper_9_21_chunk
         Filter: (val_1 < 'a'::text)
   ->  Seq Scan on _hyper_9_22_chunk
         Filter: (val_1 < 'a'::text)
   ->  Seq Scan on _hyper_9_23_chunk
         Filter: (val_1 < 'a'::text)
   ->  Seq Scan on _hyper_9_24_chunk
         Filter: (val_1 < 'a'::text)
   ->  Seq Scan on _hyper_9_25_chunk
         Filter: (val_1 < 'a'::text)
   ->  Seq Scan on _hyper_9_26_chunk
         Filter: (val_1 < 'a'::text)
   ->  Seq Scan on _hyper_9_27_chunk
         Filter: (val_1 < 'a'::text)
   ->  Seq Scan on _hyper_9_28_chunk
         Filter: (val_1 < 'a'::text)
(25 rows)

EXPLAIN (costs off) SELECT * FROM test_collation WHERE val_2 < 'a';
                        QUERY PLAN                        
----------------------------------------------------------
 Append
   ->  Custom Scan (DecompressChunk) on _hyper_9_19_chunk
         Filter: (val_2 < 'a'::text)
         ->  Seq Scan on compress_hyper_10_29_chunk
               Filter: (_ts_meta_min_2 < 'a'::text)
   ->  Custom Scan (DecompressChunk) on _hyper_9_20_chunk
         Filter: (val_2 < 'a'::text)
         ->  Seq Scan on compress_hyper_10_30_chunk
               Filter: (_ts_meta_min_2 < 'a'::text)
   ->  Seq Scan on _hyper_9_21_chunk
         Filter: (val_2 < 'a'::text)
   ->  Seq Scan on _hyper_9_22_chunk
         Filter: (val_2 < 'a'::text)
   ->  Seq Scan on _hyper_9_23_chunk
         Filter: (val_2 < 'a'::text)
   ->  Seq Scan on _hyper_9_24_chunk
         Filter: (val_2 < 'a'::text)
   ->  Seq Scan on _hyper_9_25_chunk
         Filter: (val_2 < 'a'::text)
   ->  Seq Scan on _hyper_9_26_chunk
         Filter: (val_2 < 'a'::text)
   ->  Seq Scan on _hyper_9_27_chunk
         Filter: (val_2 < 'a'::text)
   ->  Seq Scan on _hyper_9_28_chunk
         Filter: (val_2 < 'a'::text)
(25 rows)

EXPLAIN (costs off) SELECT * FROM test_collation WHERE val_1 < 'a' COLLATE "C";
                           QUERY PLAN                           
----------------------------------------------------------------
 Append
   ->  Custom Scan (DecompressChunk) on _hyper_9_19_chunk
         Filter: (val_1 < 'a'::text COLLATE "C")
         ->  Seq Scan on compress_hyper_10_29_chunk
               Filter: (_ts_meta_min_1 < 'a'::text COLLATE "C")
   ->  Custom Scan (DecompressChunk) on _hyper_9_20_chunk
         Filter: (val_1 < 'a'::text COLLATE "C")
         ->  Seq Scan on compress_hyper_10_30_chunk
               Filter: (_ts_meta_min_1 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_21_chunk
         Filter: (val_1 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_22_chunk
         Filter: (val_1 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_23_chunk
         Filter: (val_1 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_24_chunk
         Filter: (val_1 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_25_chunk
         Filter: (val_1 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_26_chunk
         Filter: (val_1 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_27_chunk
         Filter: (val_1 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_28_chunk
         Filter: (val_1 < 'a'::text COLLATE "C")
(25 rows)

EXPLAIN (costs off) SELECT * FROM test_collation WHERE val_2 < 'a' COLLATE "POSIX";
                             QUERY PLAN                             
--------------------------------------------------------------------
 Append
   ->  Custom Scan (DecompressChunk) on _hyper_9_19_chunk
         Filter: (val_2 < 'a'::text COLLATE "POSIX")
         ->  Seq Scan on compress_hyper_10_29_chunk
               Filter: (_ts_meta_min_2 < 'a'::text COLLATE "POSIX")
   ->  Custom Scan (DecompressChunk) on _hyper_9_20_chunk
         Filter: (val_2 < 'a'::text COLLATE "POSIX")
         ->  Seq Scan on compress_hyper_10_30_chunk
               Filter: (_ts_meta_min_2 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_21_chunk
         Filter: (val_2 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_22_chunk
         Filter: (val_2 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_23_chunk
         Filter: (val_2 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_24_chunk
         Filter: (val_2 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_25_chunk
         Filter: (val_2 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_26_chunk
         Filter: (val_2 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_27_chunk
         Filter: (val_2 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_28_chunk
         Filter: (val_2 < 'a'::text COLLATE "POSIX")
(25 rows)

--cannot pushdown when op collation does not match column's collation since min/max used different collation than what op needs
EXPLAIN (costs off) SELECT * FROM test_collation WHERE val_1 < 'a' COLLATE "POSIX";
                        QUERY PLAN                        
----------------------------------------------------------
 Append
   ->  Custom Scan (DecompressChunk) on _hyper_9_19_chunk
         Filter: (val_1 < 'a'::text COLLATE "POSIX")
         ->  Seq Scan on compress_hyper_10_29_chunk
   ->  Custom Scan (DecompressChunk) on _hyper_9_20_chunk
         Filter: (val_1 < 'a'::text COLLATE "POSIX")
         ->  Seq Scan on compress_hyper_10_30_chunk
   ->  Seq Scan on _hyper_9_21_chunk
         Filter: (val_1 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_22_chunk
         Filter: (val_1 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_23_chunk
         Filter: (val_1 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_24_chunk
         Filter: (val_1 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_25_chunk
         Filter: (val_1 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_26_chunk
         Filter: (val_1 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_27_chunk
         Filter: (val_1 < 'a'::text COLLATE "POSIX")
   ->  Seq Scan on _hyper_9_28_chunk
         Filter: (val_1 < 'a'::text COLLATE "POSIX")
(23 rows)

EXPLAIN (costs off) SELECT * FROM test_collation WHERE val_2 < 'a' COLLATE "C";
                        QUERY PLAN                        
----------------------------------------------------------
 Append
   ->  Custom Scan (DecompressChunk) on _hyper_9_19_chunk
         Filter: (val_2 < 'a'::text COLLATE "C")
         ->  Seq Scan on compress_hyper_10_29_chunk
   ->  Custom Scan (DecompressChunk) on _hyper_9_20_chunk
         Filter: (val_2 < 'a'::text COLLATE "C")
         ->  Seq Scan on compress_hyper_10_30_chunk
   ->  Seq Scan on _hyper_9_21_chunk
         Filter: (val_2 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_22_chunk
         Filter: (val_2 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_23_chunk
         Filter: (val_2 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_24_chunk
         Filter: (val_2 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_25_chunk
         Filter: (val_2 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_26_chunk
         Filter: (val_2 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_27_chunk
         Filter: (val_2 < 'a'::text COLLATE "C")
   ->  Seq Scan on _hyper_9_28_chunk
         Filter: (val_2 < 'a'::text COLLATE "C")
(23 rows)

--test datatypes
CREATE TABLE datatype_test(
  time timestamptz NOT NULL,
  int2_column int2,
  int4_column int4,
  int8_column int8,
  float4_column float4,
  float8_column float8,
  date_column date,
  timestamp_column timestamp,
  timestamptz_column timestamptz,
  interval_column interval,
  numeric_column numeric,
  decimal_column decimal,
  text_column text,
  char_column char
);
SELECT create_hypertable('datatype_test','time');
      create_hypertable      
-----------------------------
 (11,public,datatype_test,t)
(1 row)

ALTER TABLE datatype_test SET (timescaledb.compress);
INSERT INTO datatype_test VALUES ('2000-01-01',2,4,8,4.0,8.0,'2000-01-01','2001-01-01 12:00','2001-01-01 6:00','1 week', 3.41, 4.2, 'text', 'x');
SELECT compress_chunk(ch1.schema_name|| '.' || ch1.table_name)
FROM _timescaledb_catalog.chunk ch1, _timescaledb_catalog.hypertable ht where ch1.hypertable_id = ht.id
and ht.table_name like 'datatype_test' ORDER BY ch1.id;
              compress_chunk              
------------------------------------------
 _timescaledb_internal._hyper_11_31_chunk
(1 row)

SELECT
  attname, alg.name
FROM _timescaledb_catalog.hypertable ht
  INNER JOIN _timescaledb_catalog.hypertable_compression htc ON ht.id=htc.hypertable_id
  INNER JOIN _timescaledb_catalog.compression_algorithm alg ON alg.id=htc.compression_algorithm_id
WHERE ht.table_name='datatype_test'
ORDER BY attname;
      attname       |               name               
--------------------+----------------------------------
 char_column        | COMPRESSION_ALGORITHM_DICTIONARY
 date_column        | COMPRESSION_ALGORITHM_DELTADELTA
 decimal_column     | COMPRESSION_ALGORITHM_ARRAY
 float4_column      | COMPRESSION_ALGORITHM_GORILLA
 float8_column      | COMPRESSION_ALGORITHM_GORILLA
 int2_column        | COMPRESSION_ALGORITHM_DELTADELTA
 int4_column        | COMPRESSION_ALGORITHM_DELTADELTA
 int8_column        | COMPRESSION_ALGORITHM_DELTADELTA
 interval_column    | COMPRESSION_ALGORITHM_DICTIONARY
 numeric_column     | COMPRESSION_ALGORITHM_ARRAY
 text_column        | COMPRESSION_ALGORITHM_DICTIONARY
 time               | COMPRESSION_ALGORITHM_DELTADELTA
 timestamp_column   | COMPRESSION_ALGORITHM_DELTADELTA
 timestamptz_column | COMPRESSION_ALGORITHM_DELTADELTA
(14 rows)

--try to compress a hypertable that has a continuous aggregate
CREATE TABLE metrics(time timestamptz, device_id int, v1 float, v2 float);
SELECT create_hypertable('metrics','time');
NOTICE:  adding not-null constraint to column "time"
   create_hypertable   
-----------------------
 (13,public,metrics,t)
(1 row)

INSERT INTO metrics SELECT generate_series('2000-01-01'::timestamptz,'2000-01-10','1m'),1,0.25,0.75;
-- check expressions in view definition
CREATE VIEW cagg_expr WITH (timescaledb.continuous)
AS
SELECT
  time_bucket('1d', time) AS time,
  'Const'::text AS Const,
  4.3::numeric AS "numeric",
  first(metrics,time),
  CASE WHEN true THEN 'foo' ELSE 'bar' END,
  COALESCE(NULL,'coalesce'),
  avg(v1) + avg(v2) AS avg1,
  avg(v1+v2) AS avg2
FROM metrics
GROUP BY 1;
NOTICE:  adding index _materialized_hypertable_14_const_time_idx ON _timescaledb_internal._materialized_hypertable_14 USING BTREE(const, time)
NOTICE:  adding index _materialized_hypertable_14_numeric_time_idx ON _timescaledb_internal._materialized_hypertable_14 USING BTREE(numeric, time)
NOTICE:  adding index _materialized_hypertable_14_case_time_idx ON _timescaledb_internal._materialized_hypertable_14 USING BTREE(case, time)
NOTICE:  adding index _materialized_hypertable_14_coalesce_time_idx ON _timescaledb_internal._materialized_hypertable_14 USING BTREE(coalesce, time)
SET timescaledb.current_timestamp_mock = '2000-01-10';
REFRESH MATERIALIZED VIEW cagg_expr;
SELECT * FROM cagg_expr ORDER BY time LIMIT 5;
             time             | const | numeric |                    first                     | case | coalesce | avg1 | avg2 
------------------------------+-------+---------+----------------------------------------------+------+----------+------+------
 Fri Dec 31 16:00:00 1999 PST | Const |     4.3 | ("Sat Jan 01 00:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Sat Jan 01 16:00:00 2000 PST | Const |     4.3 | ("Sat Jan 01 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Sun Jan 02 16:00:00 2000 PST | Const |     4.3 | ("Sun Jan 02 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Mon Jan 03 16:00:00 2000 PST | Const |     4.3 | ("Mon Jan 03 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
 Tue Jan 04 16:00:00 2000 PST | Const |     4.3 | ("Tue Jan 04 16:00:00 2000 PST",1,0.25,0.75) | foo  | coalesce |    1 |    1
(5 rows)

ALTER TABLE metrics set(timescaledb.compress);
-- test rescan in compress chunk dml blocker
CREATE TABLE rescan_test(id integer NOT NULL, t timestamptz NOT NULL, val double precision, PRIMARY KEY(id, t));
SELECT create_hypertable('rescan_test', 't', chunk_time_interval => interval '1 day');
     create_hypertable     
---------------------------
 (16,public,rescan_test,t)
(1 row)

-- compression
ALTER TABLE rescan_test SET (timescaledb.compress, timescaledb.compress_segmentby = 'id');
NOTICE:  adding index _compressed_hypertable_17_id__ts_meta_sequence_num_idx ON _timescaledb_internal._compressed_hypertable_17 USING BTREE(id, _ts_meta_sequence_num)
-- INSERT dummy data
INSERT INTO rescan_test SELECT 1, time, random() FROM generate_series('2000-01-01'::timestamptz, '2000-01-05'::timestamptz, '1h'::interval) g(time);
SELECT count(*) FROM rescan_test;
 count 
-------
    97
(1 row)

-- compress first chunk
SELECT compress_chunk(ch1.schema_name|| '.' || ch1.table_name)
FROM _timescaledb_catalog.chunk ch1, _timescaledb_catalog.hypertable ht where ch1.hypertable_id = ht.id
and ht.table_name like 'rescan_test' ORDER BY ch1.id LIMIT 1;
              compress_chunk              
------------------------------------------
 _timescaledb_internal._hyper_16_36_chunk
(1 row)

-- count should be equal to count before compression
SELECT count(*) FROM rescan_test;
 count 
-------
    97
(1 row)

-- single row update is fine
UPDATE rescan_test SET val = val + 1 WHERE rescan_test.id = 1 AND rescan_test.t = '2000-01-03 00:00:00+00';
-- multi row update via WHERE is fine
UPDATE rescan_test SET val = val + 1 WHERE rescan_test.id = 1 AND rescan_test.t > '2000-01-03 00:00:00+00';
-- single row update with FROM is allowed if no compressed chunks are hit
UPDATE rescan_test SET val = tmp.val
FROM (SELECT x.id, x.t, x.val FROM unnest(array[(1, '2000-01-03 00:00:00+00', 2.045)]::rescan_test[]) AS x) AS tmp
WHERE rescan_test.id = tmp.id AND rescan_test.t = tmp.t AND rescan_test.t >= '2000-01-03';
-- single row update with FROM is blocked
\set ON_ERROR_STOP 0
UPDATE rescan_test SET val = tmp.val
FROM (SELECT x.id, x.t, x.val FROM unnest(array[(1, '2000-01-03 00:00:00+00', 2.045)]::rescan_test[]) AS x) AS tmp
WHERE rescan_test.id = tmp.id AND rescan_test.t = tmp.t;
ERROR:  cannot update/delete rows from chunk "_hyper_16_36_chunk" as it is compressed
-- bulk row update with FROM is blocked
UPDATE rescan_test SET val = tmp.val
FROM (SELECT x.id, x.t, x.val FROM unnest(array[(1, '2000-01-03 00:00:00+00', 2.045), (1, '2000-01-03 01:00:00+00', 8.045)]::rescan_test[]) AS x) AS tmp
WHERE rescan_test.id = tmp.id AND rescan_test.t = tmp.t;
ERROR:  cannot update/delete rows from chunk "_hyper_16_36_chunk" as it is compressed
\set ON_ERROR_STOP 1
